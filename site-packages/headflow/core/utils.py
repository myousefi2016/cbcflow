

from dolfin import MPI, warning
master = MPI.process_number() == 0
def headflow_warning(msg):
    if master:
        warning(msg)
def headflow_print(msg):
    if master:
        print msg


from os import getpid
from commands import getoutput
def getMyMemoryUsage():
    mypid = getpid()
    mymemory = getoutput("ps -o rss %s" % mypid).split()[1]
    return mymemory


def parallel_eval(func, point, gather=True):
    """Parallel-safe function evaluation"""
    if gather:
        if hasattr(func, 'update'):
            func.update() # dolfin dev
        else:
            func.gather() # dolfin 1.0
    if len(func.shape())==1:
        M = [0]*func.shape()[0]
    else:
        M = 0
    try:
        M = func(point)
        N = MPI.sum(1) # Succeeding processors participate in the MPI collective here
    except RuntimeError:
        N = MPI.sum(0) # Failing processors participate in the MPI collective here
        if N == 0:
            raise      # All processors failed
    if master and N > 1:
        warning("%d processors returned function value, which is unexpected (but probably ok)"%N)
    if hasattr(M, '__iter__'):
        for i in range(len(M)):
            M[i] = MPI.sum(M[i])/N
    else:
        M = MPI.sum(M)/N
    return M


def as_list(u):
    "Return a list of objects."
    if isinstance(u, (list, tuple)):
        return u
    else:
        return [u]


import urllib
class DataURLOpener(urllib.FancyURLopener):
    def __init__(self, url, filename):
        urllib.FancyURLopener.__init__(self)
        self.url = url
        self.filename = filename

    def retrieve(self, reporter=None, data=None):
        urllib.FancyURLopener.retrieve(self, self.url, self.filename, reporter, data)

    def http_error_default(self, url, fp, errcode, errmsg, headers):
        raise IOError(str(errcode)+" "+errmsg+", "+self.url)

def retrieve(filename, urlbase='http://simula.no/~jobh/headflow'):
    if not filename.endswith(".gz"):
        # Enforcing .gz extension is a quick fix to avoid trouble when
        # httpserver serves .gz file without extension, which is then
        # unreadable for dolfin.
        filename += ".gz"
    if master and not os.path.exists(filename):
        url = urlbase+'/'+filename
        warning('%s not found, fetching from %s'%(filename,url))

        targetdir = os.path.abspath(filename[:filename.rfind('/')])
        log_level = get_log_level()
        set_log_level(PROGRESS)
        progress = [Progress(filename.split('/')[-1])]
        def reporter(numblocks, blocksize, totalsize):
            progress[0] += numblocks*blocksize / totalsize

        if not os.path.isdir(targetdir):
            os.makedirs(targetdir)
        try:
            DataURLOpener(url, filename).retrieve(reporter)
        except:
            if os.path.exists(filename):
                os.remove(filename)
            raise

        del progress[0]
        set_log_level(log_level)

    MPI.barrier()
    return filename
