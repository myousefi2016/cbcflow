__author__ = "Oyvind Evju <martinal@simula.no>"
__date__ = "2013-06-25"
__copyright__ = "Copyright (C) 2013 " + __author__
__license__  = "GNU GPL version 3 or any later version"

from .paramdict import ParamDict
from .parameterized import Parameterized
from ..postprocessing import *
from .utils_pyminifier import minify

from headflow.core.utils import headflow_warning
from headflow.dol import Function, MPI, plot, File

import inspect
import re
import os


if MPI.num_processes() > 1:
    headflow_warning("Unable to plot dolfin plots in paralell. Disabling.")
    disable_plotting = True
else:
    disable_plotting = False

# Set up pylab if available
try:
    import pylab
    pylab.ion()
except:
    pylab = None
    headflow_warning("Unable to load pylab. Disable pylab plotting.")

    
from os import environ
try:
    environ['DISPLAY']
    dolfin_plotting = True
except:
    headflow_warning("Did not find display. Disabling dolfin plotting.")
    dolfin_plotting = False

def compute_check(field, t, timestep):
    "Check if field is to be computed at current time"
    # Limit by timestep interval
    s = field.params.start_timestep
    e = field.params.end_timestep
    #if s > timestep or timestep > e:
    if not (s <= timestep <= e):
        return False

    # Limit by time interval
    s = field.params.start_time
    e = field.params.end_time
    #if s > t or t > e:
    eps = 1e-10
    if not (s-eps <= t <= e+eps):
        return False
    
    # Limit by frequency (accept if no previous data)
    if timestep - field._previous_computetimestep < field.params.stride_timestep:
        return False
    if t - field._previous_computetime < field.params.stride_time:
        return False
    
    # Accept!
    return True


class DependencyException(Exception):
    def __init__(self, fieldname=None, dependency=None, timestep=None, original_exception_msg=None):
        message = ''
        if fieldname:
            message += "Dependency/dependencies not found for field %s." %fieldname
        if dependency:
            message += "Dependency %s not functioning." %dependency
        if timestep:
            message += "Relative timestep is %d. Are you trying to calculate time-derivatives at t=0?" %(name, timestep)
        if original_exception_msg:
            message += "\nOriginal exception was: "+original_exception_msg
        Exception.__init__(self, message)

class NSPostProcessor(Parameterized):
    def __init__(self, params=None):
        Parameterized.__init__(self, params)

        self._fields = {}
        self._sorted_fields_keys = [] # Topological ordering
        self._dependencies = {}
        
        self._cache = {}
        self._cache[0] = {"t": None, "timestep": None}
        self._problem = None
        
        # ParamDict for dependency fields which are not to be updated
        self._dependency_field_params = ParamDict(
            start_timestep = 1e16,
            end_timestep = -1e16,
            start_time = 1e16,
            end_time = -1e16,
            )
    @classmethod
    def default_base_params(cls):
        params = ParamDict(
            casedir="",
            )
        return params
    def _insert_in_sorted_list(self, fieldname):
        # Topological ordering of all fields, so that all dependencies are taken care of
        if fieldname in self._sorted_fields_keys:
            return
        
        # Insert all dependencies of field in list
        for dep in self._dependencies[fieldname]:
            self._insert_in_sorted_list(dep[0])
        
        # Find largest index of dependencies in sorted list
        max_index = max([0]+[self._sorted_fields_keys.index(dep[0]) for dep in self._dependencies[fieldname]])
        
        # Insert item after all its dependencies
        self._sorted_fields_keys = self._sorted_fields_keys[:max_index+1]+[fieldname]+self._sorted_fields_keys[max_index+1:]
        
    def find_dependencies(self, field):
        "Read dependencies from source (if available) from calls to PostProcessor.get command"
        # Get source        
        s = inspect.getsource(field.compute)
        s = minify(s) # Removes all comments, empty lines etc.
        
        # Remove comment blocks
        s = s.split("'''")
        s = s[0::2]
        s = ''.join(s)
        s = s.split('"""')
        s = s[0::2]
        s = ''.join(s)
        s = minify(s)

        # Get argument names for the compute function
        args = inspect.getargspec(field.compute)[0]   
        self_arg = args[0]
        pp_arg = args[1]
    
        # Read the code for dependencies
        deps = []
        deps_raw = re.findall(pp_arg+".get\((.+)\)", s)
        for dep in deps_raw:
            dep = dep.replace('"', "'")
            dep = dep.split(',')
            
            # Append default 0 if dependent timestep not specified
            if len(dep) == 1: dep.append(0)
            dep[1] = int(dep[1])
            
            # Expand cache if timestep not in cache
            if dep[1] not in self._cache:
                self._cache[dep[1]] = {}
                
            
            if "'" in dep[0]:
                # If pp.get('Velocity')
                dep[0] = dep[0].replace("'","")
            else:
                # If pp.get(self.somevariable), get the string hiding at self.somevariable
                dep[0] = eval(dep[0].replace(self_arg, "field", 1))
            
            # Expand cache
            self._cache[dep[1]][dep[0]] = None
            
            # Do not treat t and timestep as dependencies (these are not PPFields)
            if dep[0] == "t" or dep[0] == "timestep":
                self._cache[dep[1]][dep[0]] = None
                continue
            if dep[0] == "Pressure" or dep[0] == "Velocity":
                self._cache[dep[1]][dep[0]] = None
                continue
            
            # Append to dependencies
            deps.append(tuple(dep))
            
        return deps        

    def add_field(self, field):       
        # Overwrite params if field exists (e.g. created implicitly by dependencies)
        if field.name in self._fields:
            self._fields[field.name] = field

        # FIXME: Which purpose does this assertion have?
        assert field is self._fields.get(field.name, field)
        
        # Find dependencies
        deps = self.find_dependencies(field)
        
        # Expand cache
        self._cache[0][field.name] = None
        # Add dependant field to self._fields
        for d in deps:
            if d[0] not in self._fields.keys():
                cmd = d[0]+"(self._dependency_field_params)"
                # TODO: Fix eval
                self.add_field(eval(d[0]+"(params=self._dependency_field_params)"))

        self._fields[field.name] = field
        self._dependencies[field.name] = deps
        
        self._insert_in_sorted_list(field.name)
        

    def add_fields(self, fields):
        for field in fields:
            self.add_field(field)

    def get(self, name, timestep=0):
        "Called from PPFields to get data from cache"
        c = self._cache[timestep]
        
        if name not in c:
            c[name] = None
        
        v = c[name]
        
        
        if v == None:
            # Compute value
            if timestep == 0:
                f = self._fields[name]
                v = f.compute(self, self._problem)
                c[name] = v
            else:
                raise DependencyException(name, timestep)

        return v
    '''
    def _need_for(self, action, name, t, timestep):
        f = self._fields[name]
        # TODO: Match f.params[action].* and t,timestep to see if we should do this now
        doit = False
        return doit
    '''

    def _do(self, action, field):
        assert(self._cache[0][field.name]), field.name
        
        if action == "save":
            self._save(field)
        elif action == "plot":
            self._plot(field)
        else:
            error("Unknown action %s." % action)
    
    def _save(self, field):
        # Update save count
        #self._save_count += 1
        # Get/create save folder
        savedir = os.path.join(self.params.casedir, field.name)
        if not os.path.isdir(savedir):
            os.mkdir(os.path.join(self.params.casedir, field.name))
        
        
        # Get data
        data = self._cache[0][field.name]

        # Logic for first save call
        if field._compute_count == 1:
            metadata_file = open(os.path.join(savedir, 'metadata.txt'), 'w')

            # Determine proper output if not specifically provided
            if field.params.save_as == ppfield.PPField.default_params().save_as:
                if isinstance(data, (float, list, dict, int)):
                    field.params.save_as = 'txt'
                elif isinstance(data, Function):
                    field.params.save_as = ['pvd', 'xml.gz']

            # Get datatype
            field._datatype = type(data)
            #if field._datatype == dict:
            #    field._identifiers = data.keys()
            if field._datatype == Function:
                if 'pvd' in field.params.save_as:
                    field._savefiles['pvd'] = File(os.path.join(savedir, "data.pvd"))
                if 'xdmf' in field.params.save_as:
                    field._savefiles['xdmf'] = File(os.path.join(savedir, "data.xdmf"))


            # Write initial metadata
            metadata_file.write('saveformat: %s\n' %field.params.save_as)
            #if hasattr(self, "_identifiers"):
            #    metadata_file.write("identifiers: ")
            #    [metadata_file.write("%s " %k) for k in self._identifiers]
            #    metadata_file.write("\n")
            metadata_file.write('#####################################\n')

        else:
            metadata_file = open(os.path.join(savedir, 'metadata.txt'), 'a')


        # Verify that data type has not changed
        assert(isinstance(data, field._datatype))


        # Make saveformat parameters iterable (in case there are several)
        if not isinstance(field.params.save_as, list):
            field.params.save_as = [field.params.save_as]


        for saveformat in field.params.save_as:
            metadata = []
            #Write data
            if saveformat == 'txt':
                # TODO: Refine write process
                datafile = open(os.path.join(savedir, "data.txt"), 'a')
                datafile.write(str(data)+"\n")
                datafile.close()

            elif saveformat == 'xml' or saveformat == 'xml.gz':
                filename = "data%d.%s" %(field._compute_count, saveformat)
                metadata.append(('filename', filename))
                File(os.path.   join(savedir, filename)) << data

            elif saveformat == 'pvd':
                field._savefiles['pvd'] << data

            elif saveformat == 'xdmf':
                field._savefiles['xdmf'] << (data, self._cache[0]['t'])

            # Write metadata
            metadata.append(field._compute_count)
            metadata.append(('timestep', self._cache[0]['timestep']))
            metadata.append(('time', self._cache[0]['t']))
            for md in metadata:
                if isinstance(md, tuple):
                    metadata_file.write("%s=%s" %(md[0], md[1]))
                else:
                    metadata_file.write("%s" %md)
                metadata_file.write('\t')
            metadata_file.write('\n')

        metadata_file.close()
    
    def _plot(self, field):
        if disable_plotting:
            return
        
        if isinstance(self._cache[0][field.name], Function):
            if dolfin_plotting:
                self._dolfinplot(field)
        elif isinstance(self._cache[0][field.name], float):
            if pyplot:
                self._pyplot(field)
        else:
            headflow_warning("Unable to plot object %s of type %s." %(field.name, type(self._cache[0][field.name])))
    
    def _dolfinplot(self, field):
        title = "%s, t=%0.4g, timestep=%d" %(field.name, self._cache[0]["t"], self._cache[0]["timestep"])
        
        plot_object = getattr(self, "%s_plot" %field.name, None)
        if plot_object:
            plot_object.plot(self._cache[0][field.name])
        else:
            setattr(self, "%s_plot" %field.name, plot(self._cache[0][field.name], title=field.name))
            plot_object = getattr(self, "%s_plot" %field.name, None)
        plot_object.parameters["title"] = title
        
    def _pyplot(self, field):
        plot_object = getattr(self, "%s_plot" %field.name, None)
        title = "%s, t=%0.4g, timestep=%d" %(field.name, self._cache[0]["t"], self._cache[0]["timestep"])
        
        x = self._cache[0]["t"]
        y = self._cache[0][field.name]
        
        if plot_object:   
            xdata = list(plot_object.get_xdata())
            ydata = list(plot_object.get_ydata())
            
            xdata.append(x)
            ydata.append(y)
            
            plot_object.set_xdata(xdata)
            plot_object.set_ydata(ydata)
            
            pylab.axis([min(xdata), max(xdata), min(ydata), max(ydata)])
        else:
            plot_object, = pylab.plot(x, y)
            setattr(self, "%s_plot" %field.name, plot_object)
        
        plot_object.get_axes().set_title(title)
        pylab.draw()
        
    def update_all(self, u, p, t, timestep, problem):
        self._problem = problem
        "Update all PPFields"
        # Push back cache
        for tstep in sorted(self._cache)[:-1]:
            for key in self._cache[tstep].keys():
                self._cache[tstep][key] = self._cache[tstep+1][key]
        
        # Reset cache for current timestep
        for key in self._cache[0].keys():
            self._cache[0][key] = None
            
        # Set already computed fields
        self._cache[0]["t"] = t
        self._cache[0]["timestep"] = timestep
        self._cache[0]["Velocity"] = u
        self._cache[0]["Pressure"] = p

        # Update all required fields for this timestep
        for name in self._sorted_fields_keys:            
            field = self._fields[name]
            if compute_check(field, t, timestep):
                try:
                    if field._compute_count == 0:
                        field.before_first_compute(self, self._problem)
                    
                    # Only compute if not computed already (only applicable to Velocity and Pressure)
                    if self._cache[0][name] is None:
                        self._cache[0][name] = field.compute(self, self._problem)
                    field._compute_count += 1
                    for action in ["save", "plot"]:
                        if field.params[action]:
                            self._do(action, field)
                    
                except DependencyException, e:
                    headflow_warning(e.message)
                field._previous_computetime = t
                field._previous_computetimestep = timestep
        
        # Make sure dependencies are ready for next timestep
        # TODO: Make safe for increased timestep
        try:
            dt = t - self._cache[-1]["t"] # Estimate timestep
        except:
            dt = 0 # If no data for self._cache[-1]["t"]
        
        for name, dep in self._dependencies.items():
            field = self._fields[name]
            for d in dep:
                cond1 = (d[1] < 0) # If dependency requires earlier timesteps
                cond2 = compute_check(field, t+abs(d[1])*dt, timestep+abs(d[1])) # If field is to be computed in the next abs(d[1]) timesteps
                cond3 = (self._cache[0][d[0]] == None) # If dependency not calculated at this timestep
    
                if (cond1 and cond2 and cond3):
                    if field._compute_count == 0:
                        field.before_first_compute(self)
                    self._cache[0][d[0]] = self._fields[d[0]].compute(self)
        
        # TODO: Finalize fields