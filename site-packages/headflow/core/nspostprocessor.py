__author__ = "Oyvind Evju <martinal@simula.no>"
__date__ = "2013-06-25"
__copyright__ = "Copyright (C) 2013 " + __author__
__license__  = "GNU GPL version 3 or any later version"

from .paramdict import ParamDict
from .parameterized import Parameterized
from ..postprocessing import field_classes, PPField
from ..postprocessing import *
from .utils_pyminifier import minify

from headflow.core.utils import headflow_warning
from headflow.dol import Function, MPI, plot, File

import inspect
import re
import os


if MPI.num_processes() > 1:
    headflow_warning("Unable to plot dolfin plots in paralell. Disabling.")
    disable_plotting = True
else:
    disable_plotting = False

# Set up pylab if available
try:
    import pylab
    pylab.ion()
except:
    pylab = None
    headflow_warning("Unable to load pylab. Disable pylab plotting.")


from os import environ
try:
    environ['DISPLAY']
    dolfin_plotting = True
except:
    headflow_warning("Did not find display. Disabling dolfin plotting.")
    dolfin_plotting = False

def compute_at_this_time(field, t, timestep):
    "Check if field is to be computed at current time"
    # Limit by timestep interval
    s = field.params.start_timestep
    e = field.params.end_timestep
    #if s > timestep or timestep > e:
    if not (s <= timestep <= e):
        return False

    # Limit by time interval
    s = field.params.start_time
    e = field.params.end_time
    #if s > t or t > e:
    eps = 1e-10
    if not (s-eps <= t <= e+eps):
        return False

    # Limit by frequency (accept if no previous data)
    if timestep - field._previous_computetimestep < field.params.stride_timestep:
        return False
    if t - field._previous_computetime < field.params.stride_time:
        return False

    # Accept!
    return True


class DependencyException(Exception):
    def __init__(self, fieldname=None, dependency=None, timestep=None, original_exception_msg=None):
        message = ''
        if fieldname:
            message += "Dependency/dependencies not found for field %s." %fieldname
        if dependency:
            message += "Dependency %s not functioning." %dependency
        if timestep:
            message += "Relative timestep is %d. Are you trying to calculate time-derivatives at t=0?" %(name, timestep)
        if original_exception_msg:
            message += "\nOriginal exception was: "+original_exception_msg
        Exception.__init__(self, message)

from collections import defaultdict

class NSPostProcessor(Parameterized):
    def __init__(self, params=None):
        Parameterized.__init__(self, params)

        self._fields = {}
        self._sorted_fields_keys = [] # Topological ordering
        self._dependencies = {}

        self._cache = defaultdict(dict)
        self._cache[0] = {}
        self._plot_cache = {}

        self._problem = None

        self._callback = None # Signature: #def ppcallback(field, data, t, timestep)

    @classmethod
    def default_base_params(cls):
        params = ParamDict(
            casedir="",
            )
        return params

    def _insert_in_sorted_list(self, fieldname):
        # Topological ordering of all fields, so that all dependencies are taken care of

        # If already in list, assuming there's no change to dependencies
        if fieldname in self._sorted_fields_keys:
            return

        # Find largest index of dependencies in sorted list
        max_index = max([-1]+[self._sorted_fields_keys.index(dep[0]) for dep in self._dependencies[fieldname]])

        # Insert item after all its dependencies
        self._sorted_fields_keys.insert(max_index+1, fieldname)

    def find_dependencies(self, field):
        "Read dependencies from source (if available) from calls to PostProcessor.get command"

        # Get source
        s = inspect.getsource(field.compute)
        s = minify(s) # Removes all comments, empty lines etc.

        # Remove comment blocks
        s = s.split("'''")
        s = s[0::2]
        s = ''.join(s)
        s = s.split('"""')
        s = s[0::2]
        s = ''.join(s)
        s = minify(s)

        # Get argument names for the compute function
        args = inspect.getargspec(field.compute)[0]
        self_arg = args[0]
        pp_arg = args[1]

        # Read the code for dependencies
        deps = []
        deps_raw = re.findall(pp_arg+".get\((.+)\)", s)
        for dep in deps_raw:
            dep = dep.replace('"', "'")
            dep = dep.split(',')

            # Append default 0 if dependent timestep not specified
            if len(dep) == 1:
                dep.append(0)
            dep[1] = int(dep[1])

            if "'" in dep[0]:
                # If pp.get('Velocity')
                dep[0] = dep[0].replace("'","")
            else:
                # If pp.get(self.somevariable), get the string hiding at self.somevariable
                dep[0] = eval(dep[0].replace(self_arg, "field", 1))
                # TODO: Test alternative solution without eval (a matter of principle) and with better check:
                #s, n = dep[0].split(".")
                #assert s == self_arg, "Only support accessing strings through self."
                #dep[0] = getattr(field, n)
                # TODO: Possible to get variable in other cases through more introspection? Probably not necessary, just curious.

            # Ignore dependencies that are always available # FIXME: This is not true for dependencies over time!
            skiplist = ("t", "timestep", "Pressure", "Velocity")
            if dep[0] in skiplist:
                continue

            # Append to dependencies
            deps.append(tuple(dep))

        return deps

    def add_field(self, field):
        # Did we get a field name instead of a field?
        if isinstance(field, str):
            if field in self._fields.keys():
                # Field of this name already exists, no need to add it again
                return self._fields[field]
            else:
                # Create a proper field object from known field name
                field = field_classes[field](params=None)

        # Note: If field already exists, replace anyway to overwrite params, this
        # typically happens when a fields has been created implicitly by dependencies.
        # This is a bit unsafe though, the user might add a field twice with different parameters...
        # Check that at least the same name is not used for different field classes:
        assert type(field) == type(self._fields.get(field.name,field))

        # Analyse dependencies of field through magic
        deps = self.find_dependencies(field)
        #print deps

        # Add dependent fields to self._fields (this will add known fields by name)
        for depname in set(d[0] for d in deps) - set(self._fields.keys()):
            self.add_field(depname)

        # Add field to internal data structures
        self._fields[field.name] = field
        self._dependencies[field.name] = deps
        self._insert_in_sorted_list(field.name)

        # Returning the field object is useful for testing
        return field

    def add_fields(self, fields):
        return [self.add_field(field) for field in fields]

    def get(self, name, timestep=0):
        """Get the value of a named field at a particular.

        The timestep is relative to now.
        Values are computed at first request and cached.
        """
        # Check cache
        c = self._cache[timestep]
        data = c.get(name)

        # Cache miss?
        if data is None:
            if timestep == 0:
                # Ensure before_first_compute is always called once initially
                field = self._fields[name]
                if field._compute_count == 0:
                    field.before_first_compute(self, self._problem)

                # Compute value
                data = field.compute(self, self._problem)
                field._compute_count += 1
                c[name] = data
            else:
                # Cannot compute missing value from previous timestep,
                # dependency handling must have failed
                raise DependencyException(name, timestep)

        return data

    def _do(self, action, field):
        if not field.name in self._cache[0]:
            error("Field '%s' is not in cache, this should not be possible." % field.name)

        if action == "save":
            self._save(field)
        elif action == "plot":
            self._plot(field)
        elif action == "callback":
            if callable(self._callback):
                self._callback(self.field, self.get(field.name), self.get("t"), self.get("timestep"))
        else:
            error("Unknown action %s." % action)

    def _save(self, field):

        # Update save count
        #self._save_count += 1
        # Get/create save folder
        savedir = os.path.join(self.params.casedir, field.name)
        if not os.path.isdir(savedir):
            os.mkdir(os.path.join(self.params.casedir, field.name))

        # Get current time (assuming the cache contains valid 't', 'timestep' at each step)
        t = self.get("t")
        timestep = self.get('timestep')

        # Get data
        data = self.get(field.name)

        # Logic for first save call
        if field._compute_count == 1:
            # Determine proper output if not specifically provided
            if field.params.save_as == PPField.default_params().save_as:
                if isinstance(data, (float, list, dict, int)):
                    field.params.save_as = 'txt'
                elif isinstance(data, Function):
                    field.params.save_as = ['pvd', 'xml.gz']

            # Get datatype
            field._datatype = type(data)
            #if field._datatype == dict:
            #    field._identifiers = data.keys()
            if field._datatype == Function:
                if 'pvd' in field.params.save_as:
                    field._savefiles['pvd'] = File(os.path.join(savedir, "data.pvd"))
                if 'xdmf' in field.params.save_as:
                    field._savefiles['xdmf'] = File(os.path.join(savedir, "data.xdmf"))

            # Write initial metadata
            metadata_file = open(os.path.join(savedir, 'metadata.txt'), 'w')
            metadata_file.write('saveformat: %s\n' %field.params.save_as)
            #if hasattr(self, "_identifiers"):
            #    metadata_file.write("identifiers: ")
            #    [metadata_file.write("%s " %k) for k in self._identifiers]
            #    metadata_file.write("\n")
            metadata_file.write('#####################################\n')

        else:
            metadata_file = open(os.path.join(savedir, 'metadata.txt'), 'a')


        # Verify that data type has not changed
        assert(isinstance(data, field._datatype))


        # Make saveformat parameters iterable (in case there are several)
        if not isinstance(field.params.save_as, list):
            field.params.save_as = [field.params.save_as]

        for saveformat in field.params.save_as:
            metadata = []

            # Write data
            if saveformat == 'txt':
                # TODO: Refine write process
                datafile = open(os.path.join(savedir, "data.txt"), 'a')
                datafile.write(str(data)+"\n")
                datafile.close()

            elif saveformat == 'xml' or saveformat == 'xml.gz':
                filename = "data%d.%s" % (field._compute_count, saveformat)
                metadata.append(('filename', filename))
                File(os.path.join(savedir, filename)) << data

            elif saveformat == 'pvd':
                field._savefiles['pvd'] << data

            elif saveformat == 'xdmf':
                field._savefiles['xdmf'] << (data, t)

            # Write metadata
            metadata.append(field._compute_count)
            metadata.append(('timestep', timestep))
            metadata.append(('time', t))
            for md in metadata:
                if isinstance(md, tuple):
                    metadata_file.write("%s=%s" %(md[0], md[1]))
                else:
                    metadata_file.write("%s" %md)
                metadata_file.write('\t')
            metadata_file.write('\n')

        metadata_file.close()

    def _plot(self, field):
        if disable_plotting:
            return

        data = self.get(field.name)

        if isinstance(data, Function):
            if dolfin_plotting:
                self._dolfinplot(field, data)
        elif isinstance(data, float):
            if pyplot:
                self._pyplot(field, data)
        else:
            headflow_warning("Unable to plot object %s of type %s." % (field.name, type(data)))

    def _dolfinplot(self, field, data):
        # Get current time
        t = self.get("t")
        timestep = self.get('timestep')

        # Plot or re-plot
        plot_object = self._plot_cache.get(field.name)
        if plot_object is None:
            plot_object = plot(data, title=field.name)
            self._plot_cache[field.name] = plot_object
        else:
            plot_object.plot(data)

        # Set title and show
        title = "%s, t=%0.4g, timestep=%d" % (field.name, t, timestep)
        plot_object.parameters["title"] = title

    def _pyplot(self, field, data):
        # Get current time
        t = self.get("t")
        timestep = self.get('timestep')

        # Values to plot
        x = t
        y = data

        # Plot or re-plot
        plot_object = self._plot_cache.get(field.name)
        if plot_object is None:
            plot_object, = pylab.plot(x, y)
            self._plot_cache[field.name] = plot_object
        else:
            xdata = list(plot_object.get_xdata())
            ydata = list(plot_object.get_ydata())

            xdata.append(x)
            ydata.append(y)

            plot_object.set_xdata(xdata)
            plot_object.set_ydata(ydata)

            pylab.axis([min(xdata), max(xdata), min(ydata), max(ydata)])

        # Set title and show
        title = "%s, t=%0.4g, timestep=%d" % (field.name, t, timestep)
        plot_object.get_axes().set_title(title)
        pylab.draw()

    def update_all(self, u, p, t, timestep, problem):
        "Update all PPFields"

        # [martinal] ... don't like this but see the practical need
        self._problem = problem

        # Push back cache one timestep # FIXME: [martinal] I destroyed this logic in refactoring, restore!
        # [martinal] ... this is suboptimal but maybe sufficient, need to think about it
        for tstep in sorted(self._cache)[:-1]:
            for key in self._cache[tstep].keys():
                self._cache[tstep][key] = self._cache[tstep+1][key]

        # Reset cache for current timestep
        self._cache[0] = {
            "t": t,
            "timestep": timestep,
            "Velocity": u, # TODO: Convert to canonical representation as vector valued function?
            "Pressure": p,
            }

        # Update all required fields for this timestep
        for name in self._sorted_fields_keys:
            field = self._fields[name]

            # TODO: Allow different time params per action? Basically swap if and for here plus some details.
            if compute_at_this_time(field, t, timestep):
                try:
                    data = self.get(name)
                    for action in ["save", "plot", "callback"]:
                        if field.params[action]:
                            self._do(action, field)

                except DependencyException as e:
                    headflow_warning(e.message)

                # Store compute times to keep track of compute intervals
                field._previous_computetime = t
                field._previous_computetimestep = timestep

        # Make sure dependencies are ready for next timestep
        # TODO: Make safe for increased timestep
        try:
            dt = t - self.get("t", -1) # Estimate timestep
        except:
            dt = 0 # If no data for previous timestep

        # FIXME: [martinal] This logic does not cover two-level dependencies in time
        for name, dep in self._dependencies.items():
            field = self._fields[name]
            for d in dep:
                # If dependency requires earlier timesteps
                cond1 = (d[1] < 0)

                # FIXME: This check is incorrect, it only checks the endpoint not the interval
                # If field is to be computed in the next abs(d[1]) timesteps
                cond2 = compute_at_this_time(field, t+abs(d[1])*dt, timestep+abs(d[1]))

                if (cond1 and cond2):
                    # Trigger compute if dependency not calculated at this timestep
                    dummy = self.get(d[0])

    def finalize_all(self, u, p, t, timestep, problem): # TODO: Call from somewhere
        "Finalize all PPFields"

        # Update all required fields for this timestep
        for name in self._sorted_fields_keys:
            field = self._fields[name]
            field.after_final_compute(self, problem, FIXME)
